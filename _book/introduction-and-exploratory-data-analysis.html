<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Introduction and exploratory data analysis | Medical Statistics</title>
  <meta name="description" content="This course teaches the basics of R, an open-source and free environment for statistical analyses. In this course we also teach the basics transparent and reproducible research. For this, we teach RMarkdown, a tool to make dynamic reports in R." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Introduction and exploratory data analysis | Medical Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This course teaches the basics of R, an open-source and free environment for statistical analyses. In this course we also teach the basics transparent and reproducible research. For this, we teach RMarkdown, a tool to make dynamic reports in R." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Introduction and exploratory data analysis | Medical Statistics" />
  
  <meta name="twitter:description" content="This course teaches the basics of R, an open-source and free environment for statistical analyses. In this course we also teach the basics transparent and reproducible research. For this, we teach RMarkdown, a tool to make dynamic reports in R." />
  



<meta name="date" content="2022-06-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="statistical-tests---part-1.html"/>
<script src="libs/header-attrs-2.11.3/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this course</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#teachers"><i class="fa fa-check"></i>Teachers</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#goals-topics"><i class="fa fa-check"></i>Goals &amp; Topics</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#materials"><i class="fa fa-check"></i>Materials</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#programme"><i class="fa fa-check"></i>Programme</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html"><i class="fa fa-check"></i><b>1</b> Introduction and exploratory data analysis</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html#introduction-to-probabilistic-distributions"><i class="fa fa-check"></i><b>1.1</b> Introduction to probabilistic distributions</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html#motivation"><i class="fa fa-check"></i><b>1.1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.1.2" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html#discrete-random-variables"><i class="fa fa-check"></i><b>1.1.2</b> Discrete random variables</a></li>
<li class="chapter" data-level="1.1.3" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html#continuous-random-variable"><i class="fa fa-check"></i><b>1.1.3</b> Continuous random variable</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html#data-representation"><i class="fa fa-check"></i><b>1.2</b> Data representation</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html#motivating-example"><i class="fa fa-check"></i><b>1.2.1</b> Motivating example</a></li>
<li class="chapter" data-level="1.2.2" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html#working-example"><i class="fa fa-check"></i><b>1.2.2</b> Working example</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html#mean-variance"><i class="fa fa-check"></i><b>1.3</b> Mean-Variance</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html#working-example-1"><i class="fa fa-check"></i><b>1.3.1</b> Working example</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html#correlation-and-heatmap"><i class="fa fa-check"></i><b>1.4</b> Correlation and heatmap</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html#motivation-1"><i class="fa fa-check"></i><b>1.4.1</b> Motivation</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction-and-exploratory-data-analysis.html"><a href="introduction-and-exploratory-data-analysis.html#working-example-2"><i class="fa fa-check"></i><b>1.4.2</b> Working example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistical-tests---part-1.html"><a href="statistical-tests---part-1.html"><i class="fa fa-check"></i><b>2</b> Statistical tests - Part 1</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistical-tests---part-1.html"><a href="statistical-tests---part-1.html#comparing-2-groups"><i class="fa fa-check"></i><b>2.1</b> Comparing 2 groups</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="statistical-tests---part-1.html"><a href="statistical-tests---part-1.html#motivation-2"><i class="fa fa-check"></i><b>2.1.1</b> Motivation</a></li>
<li class="chapter" data-level="2.1.2" data-path="statistical-tests---part-1.html"><a href="statistical-tests---part-1.html#working-example-3"><i class="fa fa-check"></i><b>2.1.2</b> Working Example</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="statistical-tests---part-1.html"><a href="statistical-tests---part-1.html#power-of-a-statistical-test"><i class="fa fa-check"></i><b>2.2</b> Power of a statistical test</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="statistical-tests---part-1.html"><a href="statistical-tests---part-1.html#motivation-3"><i class="fa fa-check"></i><b>2.2.1</b> Motivation</a></li>
<li class="chapter" data-level="2.2.2" data-path="statistical-tests---part-1.html"><a href="statistical-tests---part-1.html#working-example-4"><i class="fa fa-check"></i><b>2.2.2</b> Working example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="common-regression-models.html"><a href="common-regression-models.html"><i class="fa fa-check"></i><b>3</b> Common regression models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="common-regression-models.html"><a href="common-regression-models.html#linear-regression"><i class="fa fa-check"></i><b>3.1</b> Linear regression</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="common-regression-models.html"><a href="common-regression-models.html#motivation-4"><i class="fa fa-check"></i><b>3.1.1</b> Motivation</a></li>
<li class="chapter" data-level="3.1.2" data-path="common-regression-models.html"><a href="common-regression-models.html#working-example-5"><i class="fa fa-check"></i><b>3.1.2</b> Working Example</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="common-regression-models.html"><a href="common-regression-models.html#logistic-regression"><i class="fa fa-check"></i><b>3.2</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="common-regression-models.html"><a href="common-regression-models.html#motivation-5"><i class="fa fa-check"></i><b>3.2.1</b> Motivation</a></li>
<li class="chapter" data-level="3.2.2" data-path="common-regression-models.html"><a href="common-regression-models.html#link-function"><i class="fa fa-check"></i><b>3.2.2</b> Link function</a></li>
<li class="chapter" data-level="3.2.3" data-path="common-regression-models.html"><a href="common-regression-models.html#the-glm-function"><i class="fa fa-check"></i><b>3.2.3</b> The <code>glm</code> function</a></li>
<li class="chapter" data-level="3.2.4" data-path="common-regression-models.html"><a href="common-regression-models.html#working-example-6"><i class="fa fa-check"></i><b>3.2.4</b> Working example</a></li>
<li class="chapter" data-level="3.2.5" data-path="common-regression-models.html"><a href="common-regression-models.html#fitted-values"><i class="fa fa-check"></i><b>3.2.5</b> Fitted values</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html"><i class="fa fa-check"></i><b>4</b> Statistical tests - Part 2</a>
<ul>
<li class="chapter" data-level="4.1" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#comparing-more-than-two-groups"><i class="fa fa-check"></i><b>4.1</b> Comparing more than two groups</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#motivation-6"><i class="fa fa-check"></i><b>4.1.1</b> Motivation</a></li>
<li class="chapter" data-level="4.1.2" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#working-examples"><i class="fa fa-check"></i><b>4.1.2</b> Working examples</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#testing-independence-in-2x2-tables"><i class="fa fa-check"></i><b>4.2</b> Testing independence in 2x2 tables</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#motivation-7"><i class="fa fa-check"></i><b>4.2.1</b> Motivation</a></li>
<li class="chapter" data-level="4.2.2" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#working-examples-1"><i class="fa fa-check"></i><b>4.2.2</b> Working examples</a></li>
<li class="chapter" data-level="4.2.3" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#general-setup"><i class="fa fa-check"></i><b>4.2.3</b> General setup</a></li>
<li class="chapter" data-level="4.2.4" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#working-examples-cont"><i class="fa fa-check"></i><b>4.2.4</b> Working examples (cont)</a></li>
<li class="chapter" data-level="4.2.5" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#the-chi-square-test"><i class="fa fa-check"></i><b>4.2.5</b> The chi-square test</a></li>
<li class="chapter" data-level="4.2.6" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#working-examples-cont-1"><i class="fa fa-check"></i><b>4.2.6</b> Working examples (cont)</a></li>
<li class="chapter" data-level="4.2.7" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#fishers-exact-test"><i class="fa fa-check"></i><b>4.2.7</b> Fisher’s exact test</a></li>
<li class="chapter" data-level="4.2.8" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#working-examples-cont-2"><i class="fa fa-check"></i><b>4.2.8</b> Working examples (cont)</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#testing-independence-in-nx2-tables"><i class="fa fa-check"></i><b>4.3</b> Testing independence in nx2 tables</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#motivation-8"><i class="fa fa-check"></i><b>4.3.1</b> Motivation</a></li>
<li class="chapter" data-level="4.3.2" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#working-examples-2"><i class="fa fa-check"></i><b>4.3.2</b> Working examples</a></li>
<li class="chapter" data-level="4.3.3" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#general-setup-1"><i class="fa fa-check"></i><b>4.3.3</b> General setup</a></li>
<li class="chapter" data-level="4.3.4" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#chi-square-test-for-nx2-tables"><i class="fa fa-check"></i><b>4.3.4</b> Chi-square test for nx2 tables</a></li>
<li class="chapter" data-level="4.3.5" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#working-examples-cont-3"><i class="fa fa-check"></i><b>4.3.5</b> Working examples (cont)</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#testing-symmetry-in-2x2-tables"><i class="fa fa-check"></i><b>4.4</b> Testing symmetry in 2x2 tables</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#motivation-9"><i class="fa fa-check"></i><b>4.4.1</b> Motivation</a></li>
<li class="chapter" data-level="4.4.2" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#working-example-7"><i class="fa fa-check"></i><b>4.4.2</b> Working example</a></li>
<li class="chapter" data-level="4.4.3" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#general-setup-2"><i class="fa fa-check"></i><b>4.4.3</b> General setup</a></li>
<li class="chapter" data-level="4.4.4" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#working-example-cont"><i class="fa fa-check"></i><b>4.4.4</b> Working example (cont)</a></li>
<li class="chapter" data-level="4.4.5" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#notes"><i class="fa fa-check"></i><b>4.4.5</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#relative-risk-and-odds-ratio"><i class="fa fa-check"></i><b>4.5</b> Relative risk and odds ratio</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#motivation-10"><i class="fa fa-check"></i><b>4.5.1</b> Motivation</a></li>
<li class="chapter" data-level="4.5.2" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#relative-risk"><i class="fa fa-check"></i><b>4.5.2</b> Relative risk</a></li>
<li class="chapter" data-level="4.5.3" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#odds-ratio"><i class="fa fa-check"></i><b>4.5.3</b> Odds ratio</a></li>
<li class="chapter" data-level="4.5.4" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#relative-risk-vs.-odds-ratio"><i class="fa fa-check"></i><b>4.5.4</b> Relative risk <em>vs.</em> odds ratio</a></li>
<li class="chapter" data-level="4.5.5" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#logistic-regression-models-cont"><i class="fa fa-check"></i><b>4.5.5</b> Logistic regression models (cont)</a></li>
<li class="chapter" data-level="4.5.6" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#poisson-regression-models"><i class="fa fa-check"></i><b>4.5.6</b> Poisson regression models</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#power-for-analysis-of-count-tables"><i class="fa fa-check"></i><b>4.6</b> Power for analysis of count tables</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#motivation-11"><i class="fa fa-check"></i><b>4.6.1</b> Motivation</a></li>
<li class="chapter" data-level="4.6.2" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#fishers-exact-test-1"><i class="fa fa-check"></i><b>4.6.2</b> Fisher’s exact test</a></li>
<li class="chapter" data-level="4.6.3" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#chi-square-test"><i class="fa fa-check"></i><b>4.6.3</b> Chi-square test</a></li>
<li class="chapter" data-level="4.6.4" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#odds-ratio-1"><i class="fa fa-check"></i><b>4.6.4</b> Odds ratio</a></li>
<li class="chapter" data-level="4.6.5" data-path="statistical-tests---part-2.html"><a href="statistical-tests---part-2.html#notes-1"><i class="fa fa-check"></i><b>4.6.5</b> Notes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>5</b> Survival analysis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="survival-analysis.html"><a href="survival-analysis.html#survival-data---introduction"><i class="fa fa-check"></i><b>5.1</b> Survival data - Introduction</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="survival-analysis.html"><a href="survival-analysis.html#motivation-12"><i class="fa fa-check"></i><b>5.1.1</b> Motivation</a></li>
<li class="chapter" data-level="5.1.2" data-path="survival-analysis.html"><a href="survival-analysis.html#working-example-8"><i class="fa fa-check"></i><b>5.1.2</b> Working example</a></li>
<li class="chapter" data-level="5.1.3" data-path="survival-analysis.html"><a href="survival-analysis.html#kaplan-meier-curve"><i class="fa fa-check"></i><b>5.1.3</b> Kaplan-Meier curve</a></li>
<li class="chapter" data-level="5.1.4" data-path="survival-analysis.html"><a href="survival-analysis.html#working-example-cont-1"><i class="fa fa-check"></i><b>5.1.4</b> Working example (cont)</a></li>
<li class="chapter" data-level="5.1.5" data-path="survival-analysis.html"><a href="survival-analysis.html#survival-data-analysis-in-r"><i class="fa fa-check"></i><b>5.1.5</b> Survival data analysis in R</a></li>
<li class="chapter" data-level="5.1.6" data-path="survival-analysis.html"><a href="survival-analysis.html#survival-data-for-groups-the-log-rank-test"><i class="fa fa-check"></i><b>5.1.6</b> Survival data for groups: the log-rank test</a></li>
<li class="chapter" data-level="5.1.7" data-path="survival-analysis.html"><a href="survival-analysis.html#working-example-cont-2"><i class="fa fa-check"></i><b>5.1.7</b> Working example (cont)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="survival-analysis.html"><a href="survival-analysis.html#survival-data---regression-models"><i class="fa fa-check"></i><b>5.2</b> Survival data - regression models</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="survival-analysis.html"><a href="survival-analysis.html#motivation-13"><i class="fa fa-check"></i><b>5.2.1</b> Motivation</a></li>
<li class="chapter" data-level="5.2.2" data-path="survival-analysis.html"><a href="survival-analysis.html#cox-proportional-hazards-model"><i class="fa fa-check"></i><b>5.2.2</b> Cox proportional-hazards model</a></li>
<li class="chapter" data-level="5.2.3" data-path="survival-analysis.html"><a href="survival-analysis.html#working-example-9"><i class="fa fa-check"></i><b>5.2.3</b> Working example</a></li>
<li class="chapter" data-level="5.2.4" data-path="survival-analysis.html"><a href="survival-analysis.html#group-specific-baseline-hazards"><i class="fa fa-check"></i><b>5.2.4</b> Group-specific baseline hazards</a></li>
<li class="chapter" data-level="5.2.5" data-path="survival-analysis.html"><a href="survival-analysis.html#the-proportional-hazards-assumption"><i class="fa fa-check"></i><b>5.2.5</b> The proportional hazards assumption</a></li>
<li class="chapter" data-level="5.2.6" data-path="survival-analysis.html"><a href="survival-analysis.html#others"><i class="fa fa-check"></i><b>5.2.6</b> Others</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="survival-analysis.html"><a href="survival-analysis.html#survival-data---power-analysis"><i class="fa fa-check"></i><b>5.3</b> Survival data - power analysis</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="survival-analysis.html"><a href="survival-analysis.html#motivation-14"><i class="fa fa-check"></i><b>5.3.1</b> Motivation</a></li>
<li class="chapter" data-level="5.3.2" data-path="survival-analysis.html"><a href="survival-analysis.html#power-and-sample-size-for-cox-regression"><i class="fa fa-check"></i><b>5.3.2</b> Power and sample size for Cox regression</a></li>
<li class="chapter" data-level="5.3.3" data-path="survival-analysis.html"><a href="survival-analysis.html#working-example-10"><i class="fa fa-check"></i><b>5.3.3</b> Working example</a></li>
<li class="chapter" data-level="5.3.4" data-path="survival-analysis.html"><a href="survival-analysis.html#minimum-sample-size"><i class="fa fa-check"></i><b>5.3.4</b> Minimum sample size</a></li>
<li class="chapter" data-level="5.3.5" data-path="survival-analysis.html"><a href="survival-analysis.html#working-example-cont-3"><i class="fa fa-check"></i><b>5.3.5</b> Working example (cont)</a></li>
<li class="chapter" data-level="5.3.6" data-path="survival-analysis.html"><a href="survival-analysis.html#reference"><i class="fa fa-check"></i><b>5.3.6</b> Reference</a></li>
<li class="chapter" data-level="5.3.7" data-path="survival-analysis.html"><a href="survival-analysis.html#notes-2"><i class="fa fa-check"></i><b>5.3.7</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="survival-analysis.html"><a href="survival-analysis.html#survival-analysis---notes"><i class="fa fa-check"></i><b>5.4</b> Survival analysis - Notes</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="survival-analysis.html"><a href="survival-analysis.html#other-types-of-censoring"><i class="fa fa-check"></i><b>5.4.1</b> Other types of censoring</a></li>
<li class="chapter" data-level="5.4.2" data-path="survival-analysis.html"><a href="survival-analysis.html#right--left--and-interval-censoring"><i class="fa fa-check"></i><b>5.4.2</b> Right-, left- and interval censoring</a></li>
<li class="chapter" data-level="5.4.3" data-path="survival-analysis.html"><a href="survival-analysis.html#type-i-and-type-ii-censoring"><i class="fa fa-check"></i><b>5.4.3</b> Type I and type II censoring</a></li>
<li class="chapter" data-level="5.4.4" data-path="survival-analysis.html"><a href="survival-analysis.html#competing-risks"><i class="fa fa-check"></i><b>5.4.4</b> Competing risks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>6</b> Exercises</a>
<ul>
<li class="chapter" data-level="6.1" data-path="exercises.html"><a href="exercises.html#chapter-1"><i class="fa fa-check"></i><b>6.1</b> Chapter 1</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="exercises.html"><a href="exercises.html#exercise-1"><i class="fa fa-check"></i><b>6.1.1</b> Exercise 1</a></li>
<li class="chapter" data-level="6.1.2" data-path="exercises.html"><a href="exercises.html#exercise-2"><i class="fa fa-check"></i><b>6.1.2</b> Exercise 2:</a></li>
<li class="chapter" data-level="6.1.3" data-path="exercises.html"><a href="exercises.html#exercise-3"><i class="fa fa-check"></i><b>6.1.3</b> Exercise 3(*)</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="exercises.html"><a href="exercises.html#chapter-2"><i class="fa fa-check"></i><b>6.2</b> Chapter 2</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="exercises.html"><a href="exercises.html#exercise-1-1"><i class="fa fa-check"></i><b>6.2.1</b> Exercise 1</a></li>
<li class="chapter" data-level="6.2.2" data-path="exercises.html"><a href="exercises.html#exercise2"><i class="fa fa-check"></i><b>6.2.2</b> Exercise2</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="exercises.html"><a href="exercises.html#chapter-3"><i class="fa fa-check"></i><b>6.3</b> Chapter 3</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="exercises.html"><a href="exercises.html#exercise-1-2"><i class="fa fa-check"></i><b>6.3.1</b> Exercise 1</a></li>
<li class="chapter" data-level="6.3.2" data-path="exercises.html"><a href="exercises.html#exercise-2-1"><i class="fa fa-check"></i><b>6.3.2</b> Exercise 2</a></li>
<li class="chapter" data-level="6.3.3" data-path="exercises.html"><a href="exercises.html#exercise-3-1"><i class="fa fa-check"></i><b>6.3.3</b> Exercise 3</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="exercises.html"><a href="exercises.html#chapter-4"><i class="fa fa-check"></i><b>6.4</b> Chapter 4</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="exercises.html"><a href="exercises.html#exercise-1-3"><i class="fa fa-check"></i><b>6.4.1</b> Exercise 1</a></li>
<li class="chapter" data-level="6.4.2" data-path="exercises.html"><a href="exercises.html#exercise-2-2"><i class="fa fa-check"></i><b>6.4.2</b> Exercise 2</a></li>
<li class="chapter" data-level="6.4.3" data-path="exercises.html"><a href="exercises.html#exercise-3-2"><i class="fa fa-check"></i><b>6.4.3</b> Exercise 3</a></li>
<li class="chapter" data-level="6.4.4" data-path="exercises.html"><a href="exercises.html#exercise-4"><i class="fa fa-check"></i><b>6.4.4</b> Exercise 4</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="exercises.html"><a href="exercises.html#chapter-5"><i class="fa fa-check"></i><b>6.5</b> Chapter 5</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="exercises.html"><a href="exercises.html#exercise-1-4"><i class="fa fa-check"></i><b>6.5.1</b> Exercise 1</a></li>
<li class="chapter" data-level="6.5.2" data-path="exercises.html"><a href="exercises.html#exercise-2-3"><i class="fa fa-check"></i><b>6.5.2</b> Exercise 2</a></li>
<li class="chapter" data-level="6.5.3" data-path="exercises.html"><a href="exercises.html#exercise-3-3"><i class="fa fa-check"></i><b>6.5.3</b> Exercise 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>7</b> Appendix</a>
<ul>
<li class="chapter" data-level="7.1" data-path="appendix.html"><a href="appendix.html#pca-analysis"><i class="fa fa-check"></i><b>7.1</b> PCA Analysis</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="appendix.html"><a href="appendix.html#motivation-15"><i class="fa fa-check"></i><b>7.1.1</b> Motivation</a></li>
<li class="chapter" data-level="7.1.2" data-path="appendix.html"><a href="appendix.html#working-example-11"><i class="fa fa-check"></i><b>7.1.2</b> Working example</a></li>
<li class="chapter" data-level="7.1.3" data-path="appendix.html"><a href="appendix.html#quick-tasks"><i class="fa fa-check"></i><b>7.1.3</b> Quick tasks</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Medical Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-and-exploratory-data-analysis" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Introduction and exploratory data analysis</h1>
<div id="introduction-to-probabilistic-distributions" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Introduction to probabilistic distributions</h2>
<div id="motivation" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Motivation</h3>
<p>In this section we will see some of the most commonly used distributions used in statistics. It is important to learn to recognize these distributions and some of their properties to better use statistical models and tests in your analysis.</p>
</div>
<div id="discrete-random-variables" class="section level3" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Discrete random variables</h3>
<p>Discrete random variables are those taking only integer values. Common distributions for those variables are the uniform distribution, the Bernoulli distribution and the binomial distribution.</p>
<p>The <strong>discrete uniform distribution</strong> assigns the exact same probability to a finite set of values. A common example is throwing a fair dice. After throwing the dice, each number 1, 2, 3, .., 6 has the same probability to be obtained, equal to 1/6.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="introduction-and-exploratory-data-analysis.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#plotting probability discrete uniform distribution</span></span>
<span id="cb1-2"><a href="introduction-and-exploratory-data-analysis.html#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="introduction-and-exploratory-data-analysis.html#cb1-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>)</span>
<span id="cb1-4"><a href="introduction-and-exploratory-data-analysis.html#cb1-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">6</span>,<span class="dv">6</span>)</span>
<span id="cb1-5"><a href="introduction-and-exploratory-data-analysis.html#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="introduction-and-exploratory-data-analysis.html#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y,<span class="at">type=</span><span class="st">&quot;h&quot;</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">6</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;p&quot;</span>)</span>
<span id="cb1-7"><a href="introduction-and-exploratory-data-analysis.html#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x,y,<span class="at">pch=</span><span class="dv">16</span>,<span class="at">cex=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>Consider another example, where you flip a coin: heads is registered as 1, and tails as 0. The <strong>Bernoulli distribution</strong> can be used to study this variable: it assigns probability <em>p</em> to 1 (heads), and <em>1-p</em> = <em>q</em> to 0 (tails).</p>
<p>You could also have a variable that can yield many possible values, which is transformed to yield only 1. For example, let us throw a fair dice and check if the number is equal to or lower than 2. The probability of a success (obtaining a value below or equal 2) corresponds to the dice returning 1 or 2, so is equal to 1/3. Therefore, the probability of throwing a number larger than 2 is 2/3 (corresponding to values 3, 4, 5, 6). The analysis of the association between covariates and the probability of success is often done via logistic regression.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="introduction-and-exploratory-data-analysis.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#plotting probability Bernoulli distribution</span></span>
<span id="cb2-2"><a href="introduction-and-exploratory-data-analysis.html#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="introduction-and-exploratory-data-analysis.html#cb2-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>)</span>
<span id="cb2-4"><a href="introduction-and-exploratory-data-analysis.html#cb2-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span><span class="sc">/</span><span class="dv">3</span>,<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span>
<span id="cb2-5"><a href="introduction-and-exploratory-data-analysis.html#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="introduction-and-exploratory-data-analysis.html#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y,<span class="at">type=</span><span class="st">&quot;h&quot;</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;p&quot;</span>)</span>
<span id="cb2-7"><a href="introduction-and-exploratory-data-analysis.html#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x,y,<span class="at">pch=</span><span class="dv">16</span>,<span class="at">cex=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>Now imagine that you throw a fair coin not once, but 10 times. Then the number of times that the result was heads can be modelled by the <strong>binomial distribution</strong>. It describes the probabilities of results of several independent throws, each of which with the same probability of success (heads).</p>
<p>If we go back to the previous dice example, we can compute the probability to obtain 4 successes (dice gives 1 or 2) in 10 trials. This can be done with the function <code>dbinom</code>. The probability is 0.2276076.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="introduction-and-exploratory-data-analysis.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#plotting probability binomial distribution</span></span>
<span id="cb3-2"><a href="introduction-and-exploratory-data-analysis.html#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="introduction-and-exploratory-data-analysis.html#cb3-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>)</span>
<span id="cb3-4"><a href="introduction-and-exploratory-data-analysis.html#cb3-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">dbinom</span>( x, <span class="dv">10</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)</span>
<span id="cb3-5"><a href="introduction-and-exploratory-data-analysis.html#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="introduction-and-exploratory-data-analysis.html#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y,<span class="at">type=</span><span class="st">&quot;h&quot;</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">10</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>),<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;p&quot;</span>)</span>
<span id="cb3-7"><a href="introduction-and-exploratory-data-analysis.html#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x,y,<span class="at">pch=</span><span class="dv">16</span>,<span class="at">cex=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="continuous-random-variable" class="section level3" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> Continuous random variable</h3>
<p>A continuous random variable can have an infinite number of possible values. Therefore, the probability to obtain any one value in particular is equal to 0. For these variables, we do not consider the probability of individual values, but instead we consider the probability associated with intervals, say all values between 0 and 1. We call the function describing the probabilities the <em>density probability function</em>. We will now look at some important continuous distributions.</p>
<p>The <strong>continuous uniform distribution</strong> has a similar definition to the discrete uniform distribution. The probability density function yields the same value across the range of possible values. To illustrate this, let us plot the density of a continuous uniform distribution between 0 and 1.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="introduction-and-exploratory-data-analysis.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot the density</span></span>
<span id="cb4-2"><a href="introduction-and-exploratory-data-analysis.html#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dunif</span>(x, <span class="at">min=</span> <span class="dv">0</span>, <span class="at">max=</span> <span class="dv">1</span>), <span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span> )</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p><strong>Quartiles</strong> are values that leave probability of 1/4, 2/4 (or 1/2) and 3/4 below them. Let us add the quartiles of the uniform distribution to the plot.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="introduction-and-exploratory-data-analysis.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot the density and quartiles</span></span>
<span id="cb5-2"><a href="introduction-and-exploratory-data-analysis.html#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dunif</span>(x, <span class="at">min=</span> <span class="dv">0</span>, <span class="at">max=</span> <span class="dv">1</span>), <span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span> )</span>
<span id="cb5-3"><a href="introduction-and-exploratory-data-analysis.html#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">qunif</span>(<span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>), <span class="at">min=</span> <span class="dv">0</span>, <span class="at">max=</span> <span class="dv">1</span>), <span class="at">col=</span> <span class="st">&#39;darkred&#39;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>The quartiles split the range of values into 4 parts, each with 1/4 probability. So the probability to observe values between 2 subsequent quartiles is 1/4, or 25%. This means that the probability to observe a value between the first and the third quartiles is equal to 1/4+1/4 = 1/2, or 50%.</p>
<p>Quartiles can also be computed for a sample: they are values that leave 1/4, 1/2 and 3/4 of the observations below them. For example, consider the following sample:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="introduction-and-exploratory-data-analysis.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">:</span><span class="dv">12</span></span></code></pre></div>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10 11 12</code></pre>
<p>Then we can take the first quartile as 3, since it has observations 1, 2, 3 up to and below it, 25% of all observations. Of course, a value larger than 3, but smaller than the next value (4) can also be used.</p>
<p>In general, for a continuous variable, the probability to observe a value between 2 given values is equal to the area under the probability density function between these two points. The generalization of the quartiles for any probability is called <strong>quantile</strong>: the 5%-quantile is the value that leaves 5% (or 0.05) of probability below it. Similarly, the 95%-quantile is the value that leaves 95% (or 0.95) of probability below it. Below we illustrate these with the probability density function for the uniform between 0 and 1.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="introduction-and-exploratory-data-analysis.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot of the density and important quantiles </span></span>
<span id="cb8-2"><a href="introduction-and-exploratory-data-analysis.html#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co">#of a continuous uniform distribution</span></span>
<span id="cb8-3"><a href="introduction-and-exploratory-data-analysis.html#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dunif</span>(x, <span class="at">min=</span> <span class="dv">0</span>, <span class="at">max=</span> <span class="dv">1</span>), <span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span> )</span>
<span id="cb8-4"><a href="introduction-and-exploratory-data-analysis.html#cb8-4" aria-hidden="true" tabindex="-1"></a>mcol <span class="ot">&lt;-</span> <span class="st">&#39;darkred&#39;</span></span>
<span id="cb8-5"><a href="introduction-and-exploratory-data-analysis.html#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">qunif</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="at">min=</span> <span class="dv">0</span>, <span class="at">max=</span> <span class="dv">1</span>), <span class="at">col=</span> mcol)</span>
<span id="cb8-6"><a href="introduction-and-exploratory-data-analysis.html#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.1</span>, <span class="fl">1.1</span>, <span class="at">col =</span> mcol, <span class="at">labels =</span> <span class="st">&quot;0.025&quot;</span>)</span>
<span id="cb8-7"><a href="introduction-and-exploratory-data-analysis.html#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.9</span>, <span class="fl">1.1</span>, <span class="at">col =</span> mcol, <span class="at">labels =</span> <span class="st">&quot;0.975&quot;</span>)</span>
<span id="cb8-8"><a href="introduction-and-exploratory-data-analysis.html#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="introduction-and-exploratory-data-analysis.html#cb8-9" aria-hidden="true" tabindex="-1"></a>mcol <span class="ot">&lt;-</span> <span class="st">&#39;purple&#39;</span></span>
<span id="cb8-10"><a href="introduction-and-exploratory-data-analysis.html#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">qunif</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.95</span>), <span class="at">min=</span> <span class="dv">0</span>, <span class="at">max=</span> <span class="dv">1</span>), <span class="at">col=</span> mcol)</span>
<span id="cb8-11"><a href="introduction-and-exploratory-data-analysis.html#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.15</span>, <span class="fl">1.2</span>, <span class="at">col =</span> mcol, <span class="at">labels =</span> <span class="st">&quot;0&quot;</span>)</span>
<span id="cb8-12"><a href="introduction-and-exploratory-data-analysis.html#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.85</span>, <span class="fl">1.2</span>, <span class="at">col =</span> mcol, <span class="at">labels =</span> <span class="st">&quot;0.95&quot;</span>)</span>
<span id="cb8-13"><a href="introduction-and-exploratory-data-analysis.html#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="introduction-and-exploratory-data-analysis.html#cb8-14" aria-hidden="true" tabindex="-1"></a>mcol <span class="ot">&lt;-</span> <span class="st">&#39;darkorange&#39;</span></span>
<span id="cb8-15"><a href="introduction-and-exploratory-data-analysis.html#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">qunif</span>(<span class="fu">c</span>(<span class="fl">0.05</span>, <span class="dv">1</span>), <span class="at">min=</span> <span class="dv">0</span>, <span class="at">max=</span> <span class="dv">1</span>), <span class="at">col=</span> mcol)</span>
<span id="cb8-16"><a href="introduction-and-exploratory-data-analysis.html#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.2</span>, <span class="fl">1.3</span>, <span class="at">col =</span> mcol, <span class="at">labels =</span> <span class="st">&quot;0.05&quot;</span>)</span>
<span id="cb8-17"><a href="introduction-and-exploratory-data-analysis.html#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.8</span>, <span class="fl">1.3</span>, <span class="at">col =</span> mcol, <span class="at">labels =</span> <span class="st">&quot;1&quot;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Quantiles are used in statistical testing to build the confidence intervals and compute p-values. Similar to quartiles, we can also obtain quantiles for samples of values. For example, for the sample</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="introduction-and-exploratory-data-analysis.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">:</span><span class="dv">10</span></span></code></pre></div>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10</code></pre>
<p>the 10% quantile is 1 (or any number larger than 1 but smaller than 2), and the 90% quantile is 9.</p>
<p>The most common distribution encountered in the nature is the normal or Gaussian distribution. This distribution is symmetric, and is defined by its expectation <span class="math inline">\(\mu\)</span> and its variance <span class="math inline">\(\sigma^2\)</span>, i.e. <span class="math inline">\(N(\mu,\sigma^2)\)</span>. Its values range from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>. Note that it is important to make the difference between the expectation of the distribution and the sample mean derived from this distribution. Indeed, these two will be equal only if all possible samples are included to compute sample mean.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="introduction-and-exploratory-data-analysis.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot of the density and quantiles of a normal distribution</span></span>
<span id="cb11-2"><a href="introduction-and-exploratory-data-analysis.html#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">from =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">to =</span> <span class="dv">5</span>)</span>
<span id="cb11-3"><a href="introduction-and-exploratory-data-analysis.html#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">qnorm</span>(<span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.75</span>), <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="at">col=</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb11-4"><a href="introduction-and-exploratory-data-analysis.html#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">qnorm</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="at">col=</span> <span class="st">&#39;darkred&#39;</span>)</span>
<span id="cb11-5"><a href="introduction-and-exploratory-data-analysis.html#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">qnorm</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.95</span>), <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="at">col=</span> <span class="st">&#39;purple&#39;</span>)</span>
<span id="cb11-6"><a href="introduction-and-exploratory-data-analysis.html#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">qnorm</span>(<span class="fu">c</span>(<span class="fl">0.05</span>, <span class="dv">1</span>), <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="at">col=</span> <span class="st">&#39;darkorange&#39;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>The normal distribution is often referred to as the <em>Gaussian</em> distribution, due to the work of C. F. Gauss in this area. The normal distribution with mean <span class="math inline">\(\mu=\)</span> 0 and variance <span class="math inline">\(\sigma^2=\)</span> 1 is referred to as the standard normal distribution.</p>
<p>This distribution is very important in statistics due to one of its properties, the <strong>central limit theorem</strong>: it states that if you have a population with expectation <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> and take sufficiently large random samples from the population with replacement, then the sample means will follow approximately a normal distribution. This will hold true regardless of whether the source population is normal or skewed, provided the sample size is sufficiently large (usually <em>n</em> &gt; 30) and the variance of the original distribution is finite.</p>
<p>Let’s illustrate the central limit theorem with the gamma distribution that will be seen in another chapter of this course. First consider the probability density function of the gamma distribution:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="introduction-and-exploratory-data-analysis.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dgamma</span>(x, <span class="at">shape =</span> <span class="dv">1</span>, <span class="at">rate =</span> <span class="dv">1</span>), <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">5</span>, <span class="at">col=</span> <span class="st">&#39;blue&#39;</span></span>
<span id="cb12-2"><a href="introduction-and-exploratory-data-analysis.html#cb12-2" aria-hidden="true" tabindex="-1"></a>      , <span class="at">ylab=</span> <span class="st">&#39;density&#39;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Now we simulate 500 samples, each of 30 values, from the same gamma distribution. We then compute the mean for each sample.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="introduction-and-exploratory-data-analysis.html#cb13-1" aria-hidden="true" tabindex="-1"></a>mean.samples <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb13-2"><a href="introduction-and-exploratory-data-analysis.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>){</span>
<span id="cb13-3"><a href="introduction-and-exploratory-data-analysis.html#cb13-3" aria-hidden="true" tabindex="-1"></a>  data.sample <span class="ot">&lt;-</span> <span class="fu">rgamma</span>( <span class="dv">30</span> , <span class="at">shape =</span> <span class="dv">1</span>, <span class="at">rate =</span> <span class="dv">1</span>)</span>
<span id="cb13-4"><a href="introduction-and-exploratory-data-analysis.html#cb13-4" aria-hidden="true" tabindex="-1"></a>  mean.samples <span class="ot">&lt;-</span> <span class="fu">c</span>(mean.samples, <span class="fu">mean</span>(data.sample))</span>
<span id="cb13-5"><a href="introduction-and-exploratory-data-analysis.html#cb13-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>The histogram of the means computed is:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="introduction-and-exploratory-data-analysis.html#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(mean.samples, <span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Essentially the arithmetic mean smoothes out small random variations between samples, which can go in either direction. As a result, its distribution will not be skewed, as the original observations, but symmetric and with little variation around its own mean. This is then the normal distribution.</p>
<p>The chi-square distribution, represented by <span class="math inline">\(\chi^2\)</span> is defined at the sum of <em>k</em> squared independent random variables, each following a normal distribution with mean 0 and variance equal to 1. The chi-square only has one parameter, <em>k</em>, called <em>degrees of freedom</em>. This distribution is often used for statistical testing. Its probability density function is shown below.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="introduction-and-exploratory-data-analysis.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot of the density and quantiles of a chi square distribution </span></span>
<span id="cb15-2"><a href="introduction-and-exploratory-data-analysis.html#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co">#with 1 degree of freedom</span></span>
<span id="cb15-3"><a href="introduction-and-exploratory-data-analysis.html#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dchisq</span>(x, <span class="at">df =</span> <span class="dv">1</span>), <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">5</span>)</span>
<span id="cb15-4"><a href="introduction-and-exploratory-data-analysis.html#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">qchisq</span>(<span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.75</span>), <span class="at">df =</span> <span class="dv">1</span>), <span class="at">col=</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb15-5"><a href="introduction-and-exploratory-data-analysis.html#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">qchisq</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="at">df =</span> <span class="dv">1</span>), <span class="at">col=</span> <span class="st">&#39;darkred&#39;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Finally, the Student’s t distribution is very important as it is used in the well-known Student’s-t test to compare means between two samples. This distribution is defined by its number of degrees of freedom <span class="math inline">\(k\)</span>. This distribution, as the normal distribution, is symmetric, as we can see from its probability density function below.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="introduction-and-exploratory-data-analysis.html#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Plot of the density and quantiles of a chi square distribution </span></span>
<span id="cb16-2"><a href="introduction-and-exploratory-data-analysis.html#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co">#with 2 degree of freedom</span></span>
<span id="cb16-3"><a href="introduction-and-exploratory-data-analysis.html#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dt</span>(x, <span class="at">df =</span> <span class="dv">2</span>), <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">from =</span> <span class="sc">-</span><span class="dv">10</span>, <span class="at">to =</span> <span class="dv">10</span>)</span>
<span id="cb16-4"><a href="introduction-and-exploratory-data-analysis.html#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">qt</span>(<span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.75</span>), <span class="at">df =</span> <span class="dv">2</span>), <span class="at">col=</span> <span class="st">&#39;darkgreen&#39;</span>)</span>
<span id="cb16-5"><a href="introduction-and-exploratory-data-analysis.html#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">qt</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="at">df =</span> <span class="dv">2</span>), <span class="at">col=</span> <span class="st">&#39;darkred&#39;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>This distribution has the same <em>bell</em> shape as the normal distribution. However, this shape is wider for the Student’s-t, becoming narrower as the number of degrees of freedom increases.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="introduction-and-exploratory-data-analysis.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb17-2"><a href="introduction-and-exploratory-data-analysis.html#cb17-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">to =</span> <span class="dv">5</span>, <span class="at">by =</span> .<span class="dv">1</span>)</span>
<span id="cb17-3"><a href="introduction-and-exploratory-data-analysis.html#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dt</span>(x, <span class="at">df =</span> <span class="dv">1</span>), <span class="at">col =</span> <span class="st">&#39;purple&#39;</span>, <span class="at">from =</span> <span class="sc">-</span><span class="dv">10</span>, <span class="at">to =</span> <span class="dv">10</span>, </span>
<span id="cb17-4"><a href="introduction-and-exploratory-data-analysis.html#cb17-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">&quot;t with 1 d.f.&quot;</span>, </span>
<span id="cb17-5"><a href="introduction-and-exploratory-data-analysis.html#cb17-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.4</span>), <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb17-6"><a href="introduction-and-exploratory-data-analysis.html#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="at">col =</span> <span class="st">&#39;black&#39;</span>)</span>
<span id="cb17-7"><a href="introduction-and-exploratory-data-analysis.html#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;normal&quot;</span>, <span class="st">&quot;t&quot;</span>), <span class="at">lty =</span> <span class="st">&quot;solid&quot;</span></span>
<span id="cb17-8"><a href="introduction-and-exploratory-data-analysis.html#cb17-8" aria-hidden="true" tabindex="-1"></a>       ,</span>
<span id="cb17-9"><a href="introduction-and-exploratory-data-analysis.html#cb17-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;purple&quot;</span>))</span>
<span id="cb17-10"><a href="introduction-and-exploratory-data-analysis.html#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="introduction-and-exploratory-data-analysis.html#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dt</span>(x, <span class="at">df =</span> <span class="dv">10</span>), <span class="at">col =</span> <span class="st">&#39;purple&#39;</span>, <span class="at">from =</span> <span class="sc">-</span><span class="dv">10</span>, <span class="at">to =</span> <span class="dv">10</span>,</span>
<span id="cb17-12"><a href="introduction-and-exploratory-data-analysis.html#cb17-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">&quot;t with 10 d.f.&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb17-13"><a href="introduction-and-exploratory-data-analysis.html#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="at">col =</span> <span class="st">&#39;black&#39;</span>)</span>
<span id="cb17-14"><a href="introduction-and-exploratory-data-analysis.html#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;normal&quot;</span>, <span class="st">&quot;t&quot;</span>), <span class="at">lty =</span> <span class="st">&quot;solid&quot;</span>, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;purple&quot;</span>))</span>
<span id="cb17-15"><a href="introduction-and-exploratory-data-analysis.html#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="introduction-and-exploratory-data-analysis.html#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dt</span>(x, <span class="at">df =</span> <span class="dv">30</span>), <span class="at">col =</span> <span class="st">&#39;purple&#39;</span>, <span class="at">from =</span> <span class="sc">-</span><span class="dv">10</span>, <span class="at">to =</span> <span class="dv">10</span>, </span>
<span id="cb17-17"><a href="introduction-and-exploratory-data-analysis.html#cb17-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">main =</span> <span class="st">&quot;t with 30 d.f.&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb17-18"><a href="introduction-and-exploratory-data-analysis.html#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>), <span class="at">col =</span> <span class="st">&#39;black&#39;</span>)</span>
<span id="cb17-19"><a href="introduction-and-exploratory-data-analysis.html#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;normal&quot;</span>, <span class="st">&quot;t&quot;</span>), <span class="at">lty =</span> <span class="st">&quot;solid&quot;</span>, </span>
<span id="cb17-20"><a href="introduction-and-exploratory-data-analysis.html#cb17-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;purple&quot;</span>))</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<hr />
<blockquote>
<p><em>Quick task(s)</em>:</p>
<p>Solve <a href="_book/01-Introduction-to-probabilistic-distributions.tasks.nocode.html">the task(s)</a>, and check your solution(s) <a href="_book/01-Introduction-to-probabilistic-distributions.tasks.code.html">here</a>.</p>
</blockquote>
<hr />
</div>
</div>
<div id="data-representation" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Data representation</h2>
<div id="motivating-example" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Motivating example</h3>
<p>A researcher receives the dataset <code>decathlon2</code> from the <code>factoextra</code> package. This dataset describe the performances of several athletes in two different sport events. Before starting any analysis, the researcher wants to explore the data, for example by visualising the data.</p>
<p>Below we load the data.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="introduction-and-exploratory-data-analysis.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span></code></pre></div>
<pre><code>## Warning: le package &#39;factoextra&#39; a été compilé avec la version R 4.1.1</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="introduction-and-exploratory-data-analysis.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(decathlon2)</span>
<span id="cb20-2"><a href="introduction-and-exploratory-data-analysis.html#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Display a description of the dataset</span></span>
<span id="cb20-3"><a href="introduction-and-exploratory-data-analysis.html#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(decathlon2)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    27 obs. of  13 variables:
##  $ X100m       : num  11 10.8 11 11.3 11.1 ...
##  $ Long.jump   : num  7.58 7.4 7.23 7.09 7.3 7.31 6.81 7.56 6.97 7.27 ...
##  $ Shot.put    : num  14.8 14.3 14.2 15.2 13.5 ...
##  $ High.jump   : num  2.07 1.86 1.92 2.1 2.01 2.13 1.95 1.86 1.95 1.98 ...
##  $ X400m       : num  49.8 49.4 48.9 50.4 48.6 ...
##  $ X110m.hurdle: num  14.7 14.1 15 15.3 14.2 ...
##  $ Discus      : num  43.8 50.7 40.9 46.3 45.7 ...
##  $ Pole.vault  : num  5.02 4.92 5.32 4.72 4.42 4.42 4.92 4.82 4.72 4.62 ...
##  $ Javeline    : num  63.2 60.1 62.8 63.4 55.4 ...
##  $ X1500m      : num  292 302 280 276 268 ...
##  $ Rank        : int  1 2 4 5 7 8 9 10 11 12 ...
##  $ Points      : int  8217 8122 8067 8036 8004 7995 7802 7733 7708 7651 ...
##  $ Competition : Factor w/ 2 levels &quot;Decastar&quot;,&quot;OlympicG&quot;: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="introduction-and-exploratory-data-analysis.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first lines of the table</span></span>
<span id="cb22-2"><a href="introduction-and-exploratory-data-analysis.html#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(decathlon2)</span></code></pre></div>
<pre><code>##           X100m Long.jump Shot.put High.jump X400m X110m.hurdle Discus
## SEBRLE    11.04      7.58    14.83      2.07 49.81        14.69  43.75
## CLAY      10.76      7.40    14.26      1.86 49.37        14.05  50.72
## BERNARD   11.02      7.23    14.25      1.92 48.93        14.99  40.87
## YURKOV    11.34      7.09    15.19      2.10 50.42        15.31  46.26
## ZSIVOCZKY 11.13      7.30    13.48      2.01 48.62        14.17  45.67
## McMULLEN  10.83      7.31    13.76      2.13 49.91        14.38  44.41
##           Pole.vault Javeline X1500m Rank Points Competition
## SEBRLE          5.02    63.19  291.7    1   8217    Decastar
## CLAY            4.92    60.15  301.5    2   8122    Decastar
## BERNARD         5.32    62.77  280.1    4   8067    Decastar
## YURKOV          4.72    63.44  276.4    5   8036    Decastar
## ZSIVOCZKY       4.42    55.37  268.0    7   8004    Decastar
## McMULLEN        4.42    56.37  285.1    8   7995    Decastar</code></pre>
<p>You will use this dataset in exercises.</p>
</div>
<div id="working-example" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Working example</h3>
<p>As a small, simple example, we consider the following simulated dataset: 2 continuous variables, <code>scoreX</code> and <code>scoreY</code>, and a categorical variable representing the membership of group A or B.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="introduction-and-exploratory-data-analysis.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">352</span>)</span>
<span id="cb24-2"><a href="introduction-and-exploratory-data-analysis.html#cb24-2" aria-hidden="true" tabindex="-1"></a>sample.size<span class="ot">&lt;-</span><span class="dv">60</span></span>
<span id="cb24-3"><a href="introduction-and-exploratory-data-analysis.html#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="introduction-and-exploratory-data-analysis.html#cb24-4" aria-hidden="true" tabindex="-1"></a>scoreX <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(sample.size, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="fl">1.2</span>)</span>
<span id="cb24-5"><a href="introduction-and-exploratory-data-analysis.html#cb24-5" aria-hidden="true" tabindex="-1"></a>scoreY <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(sample.size, <span class="at">shape =</span> <span class="dv">2</span>, <span class="at">scale =</span> <span class="dv">1</span>)</span>
<span id="cb24-6"><a href="introduction-and-exploratory-data-analysis.html#cb24-6" aria-hidden="true" tabindex="-1"></a>group <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&#39;A&#39;</span>, <span class="st">&#39;B&#39;</span>), <span class="at">each =</span> sample.size<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb24-7"><a href="introduction-and-exploratory-data-analysis.html#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="introduction-and-exploratory-data-analysis.html#cb24-8" aria-hidden="true" tabindex="-1"></a>dataset <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">scoreX =</span> scoreX, <span class="at">scoreY =</span> scoreY,</span>
<span id="cb24-9"><a href="introduction-and-exploratory-data-analysis.html#cb24-9" aria-hidden="true" tabindex="-1"></a>                      <span class="at">group =</span> group, <span class="at">stringsAsFactors =</span> T)</span></code></pre></div>
<p>Before doing any statistical analysis, it is important to look at the distributions of the variables available. Indeed, looking at the shape of the distributions can help choosing adequate analysis methods. Let’s look at the distribution of the variable <code>scoreX</code> by plotting an histogram of the variable. This can be done using the function hist in R:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="introduction-and-exploratory-data-analysis.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">#plot the histogram of a variable</span></span>
<span id="cb25-2"><a href="introduction-and-exploratory-data-analysis.html#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(dataset<span class="sc">$</span>scoreX, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>The histogram displays bars representing counts of the number of observations falling into specific bins (intervals of values). This gives us an idea about the shape of the distribution of a variable (in the example above, of <code>scoreX</code>). As we simulated values for =<code>scoreX</code> using a normal distribution, we expect the histogram to reflect this - be symmetric and to not have too many extremen values. Compare the histogram above to the one for the variable <code>scoreY</code>:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="introduction-and-exploratory-data-analysis.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">#plot the histogram of a variable</span></span>
<span id="cb26-2"><a href="introduction-and-exploratory-data-analysis.html#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(dataset<span class="sc">$</span>scoreY, <span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>We can also display histograms per group to compare the shape of the distributions between two groups. To do so we need to split the data in two:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="introduction-and-exploratory-data-analysis.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Creation dataset group A</span></span>
<span id="cb27-2"><a href="introduction-and-exploratory-data-analysis.html#cb27-2" aria-hidden="true" tabindex="-1"></a>data.A <span class="ot">&lt;-</span> dataset[dataset<span class="sc">$</span>group <span class="sc">==</span> <span class="st">&#39;A&#39;</span>,]</span>
<span id="cb27-3"><a href="introduction-and-exploratory-data-analysis.html#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="introduction-and-exploratory-data-analysis.html#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Creation dataset group B</span></span>
<span id="cb27-5"><a href="introduction-and-exploratory-data-analysis.html#cb27-5" aria-hidden="true" tabindex="-1"></a>data.B <span class="ot">&lt;-</span> dataset[dataset<span class="sc">$</span>group <span class="sc">==</span> <span class="st">&#39;B&#39;</span>,]</span>
<span id="cb27-6"><a href="introduction-and-exploratory-data-analysis.html#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="introduction-and-exploratory-data-analysis.html#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">#plot the histograms of scoreX for both groups</span></span>
<span id="cb27-8"><a href="introduction-and-exploratory-data-analysis.html#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb27-9"><a href="introduction-and-exploratory-data-analysis.html#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data.A<span class="sc">$</span>scoreX, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">main =</span> <span class="st">&#39;histogram scoreX group A&#39;</span> )</span>
<span id="cb27-10"><a href="introduction-and-exploratory-data-analysis.html#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data.B<span class="sc">$</span>scoreX, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">main =</span> <span class="st">&#39;histogram scoreX group B&#39;</span> )</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Here, the histograms of subsets of <code>scoreX</code> look quite different. However, the values from both groups are drawn using the same distribution. The differences observed are only due to randomness. We can, for example, add to these histograms the density plot of the distribution used to simulate the <code>scoreX</code> variable:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="introduction-and-exploratory-data-analysis.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">#plot the histograms of scoreX for both groups with added density</span></span>
<span id="cb28-2"><a href="introduction-and-exploratory-data-analysis.html#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb28-3"><a href="introduction-and-exploratory-data-analysis.html#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="introduction-and-exploratory-data-analysis.html#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="introduction-and-exploratory-data-analysis.html#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data.A<span class="sc">$</span>scoreX, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">prob =</span> <span class="cn">TRUE</span>, </span>
<span id="cb28-6"><a href="introduction-and-exploratory-data-analysis.html#cb28-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&#39;histogram scoreX group A&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.4</span>), <span class="at">xlim=</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">8</span>))</span>
<span id="cb28-7"><a href="introduction-and-exploratory-data-analysis.html#cb28-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">to =</span> <span class="dv">15</span>, <span class="at">by =</span> .<span class="dv">1</span>)</span>
<span id="cb28-8"><a href="introduction-and-exploratory-data-analysis.html#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="fl">1.2</span>), <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb28-9"><a href="introduction-and-exploratory-data-analysis.html#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data.B<span class="sc">$</span>scoreX, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">prob =</span> <span class="cn">TRUE</span>, </span>
<span id="cb28-10"><a href="introduction-and-exploratory-data-analysis.html#cb28-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&#39;histogram scoreX group B&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.4</span>), <span class="at">xlim=</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">8</span>) )</span>
<span id="cb28-11"><a href="introduction-and-exploratory-data-analysis.html#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="fl">1.2</span>), <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>As we can see, it is not possible to determine from these plots that the distributions of <code>scoreX</code> in both groups are different. This is why statistical testing is needed: to check if apparent differences could be due to chance or not.</p>
<p>Another important and useful way to represent the data are boxplots. Boxplots are graphical representations of summary measures of a distribution represented, as the name indicates, in the shape of a box. We will draw a boxplot of the variable <code>scoreY</code>:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="introduction-and-exploratory-data-analysis.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Boxplot of a variable</span></span>
<span id="cb29-2"><a href="introduction-and-exploratory-data-analysis.html#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(dataset<span class="sc">$</span>scoreY, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;scoreY&#39;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>The box represents the space between the first and the third quartiles of the variable. The thick horizontal line represents the median of the variable, i.e. the second quartile leaving 50% of values below it. Finally, the top and bottom lines represent a space equal to 1.5 the boxsize from the nearest edge of the box. Any values above or below these lines are represented as points and are considered as extreme values, and possible outliers.</p>
<p>To make boxplots of the same variable for different groups is really easy, by using a formula as shown below:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="introduction-and-exploratory-data-analysis.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Boxplot of a variable for different gruops</span></span>
<span id="cb30-2"><a href="introduction-and-exploratory-data-analysis.html#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(dataset<span class="sc">$</span>scoreY <span class="sc">~</span> dataset<span class="sc">$</span>group, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;scoreY&#39;</span></span>
<span id="cb30-3"><a href="introduction-and-exploratory-data-analysis.html#cb30-3" aria-hidden="true" tabindex="-1"></a>        , <span class="at">xlab =</span> <span class="st">&#39;group&#39;</span>)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>As we can see in these boxplots, the median value for both groups is similar but the group B box is wider, indicating more variations in this group. Again, statistical methods are needed to prove if this difference is real or not.</p>
<hr />
<blockquote>
<p><em>Quick task(s)</em>:</p>
<p>Solve <a href="_book/02-Data-representation.tasks.nocode.html">the task(s)</a>, and check your solution(s) <a href="_book/02-Data-representation.tasks.code.html">here</a>.</p>
</blockquote>
<hr />
</div>
</div>
<div id="mean-variance" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Mean-Variance</h2>
<div id="working-example-1" class="section level3" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Working example</h3>
<p>We now want to compute summary measures for the variables in a dataset. Consider the same dataset, <code>dataset</code>, that we simulated in the previous part.</p>
<p>By looking at the histograms and boxplots, we noticed possible differences between the variables’ values in the different groups. We now want to derive summary measures to see if they corroborate what the eyes could see. The most common summary measures of continuous variables are the mean and the standard deviation.</p>
<p>The sample mean represents the central value of the combined values of all samples for a specific variable. The mean is computed as the sum of all the values of a variable divided by the total number of values measured:</p>
<p><span class="math inline">\(\overline{x} = \frac{\sum_{i}^{N}(x_i)}{N}\)</span></p>
<p>To compute mean values of <code>scoreX</code> and <code>scoreY</code> for the groups <code>A</code> and <code>B</code>.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="introduction-and-exploratory-data-analysis.html#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Creation dataset group A containing only scoreX and scoreY</span></span>
<span id="cb31-2"><a href="introduction-and-exploratory-data-analysis.html#cb31-2" aria-hidden="true" tabindex="-1"></a>data.A <span class="ot">&lt;-</span> dataset[dataset<span class="sc">$</span>group <span class="sc">==</span> <span class="st">&#39;A&#39;</span>, <span class="fu">c</span>(<span class="st">&#39;scoreX&#39;</span>, <span class="st">&#39;scoreY&#39;</span>)]</span>
<span id="cb31-3"><a href="introduction-and-exploratory-data-analysis.html#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="introduction-and-exploratory-data-analysis.html#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Creation dataset group B containing only scoreX and scoreY</span></span>
<span id="cb31-5"><a href="introduction-and-exploratory-data-analysis.html#cb31-5" aria-hidden="true" tabindex="-1"></a>data.B <span class="ot">&lt;-</span> dataset[dataset<span class="sc">$</span>group <span class="sc">==</span> <span class="st">&#39;B&#39;</span>, <span class="fu">c</span>(<span class="st">&#39;scoreX&#39;</span>, <span class="st">&#39;scoreY&#39;</span>)]</span>
<span id="cb31-6"><a href="introduction-and-exploratory-data-analysis.html#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="introduction-and-exploratory-data-analysis.html#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co">#Computation of the mean for each variable of the dataset for group A</span></span>
<span id="cb31-8"><a href="introduction-and-exploratory-data-analysis.html#cb31-8" aria-hidden="true" tabindex="-1"></a>mean.variables.groupA <span class="ot">&lt;-</span> <span class="fu">apply</span>(data.A, <span class="dv">2</span>, mean, <span class="at">na.rm=</span>T)</span>
<span id="cb31-9"><a href="introduction-and-exploratory-data-analysis.html#cb31-9" aria-hidden="true" tabindex="-1"></a>mean.variables.groupA</span></code></pre></div>
<pre><code>##   scoreX   scoreY 
## 4.880274 1.750616</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="introduction-and-exploratory-data-analysis.html#cb33-1" aria-hidden="true" tabindex="-1"></a>data.A</span></code></pre></div>
<pre><code>##      scoreX     scoreY
## 1  5.679002 0.53389766
## 2  1.810394 0.39127041
## 3  3.794993 1.01559188
## 4  5.691155 0.06849886
## 5  3.655173 1.42978089
## 6  2.996220 2.53244125
## 7  5.607361 1.49633795
## 8  7.283853 3.78528618
## 9  5.930352 2.94015306
## 10 7.244870 1.69968558
## 11 4.160336 4.49709044
## 12 1.985166 0.23456286
## 13 4.951650 1.69578956
## 14 3.784455 0.96296143
## 15 6.414988 4.29071898
## 16 5.336681 2.67268555
## 17 4.434049 2.34449025
## 18 5.087762 2.44975321
## 19 5.402171 0.44416274
## 20 4.198960 0.22505876
## 21 5.123555 1.90313042
## 22 3.583251 4.09168428
## 23 4.355833 0.46274765
## 24 4.544629 1.77943488
## 25 6.641351 1.30219871
## 26 6.991088 3.20300464
## 27 4.901021 0.84321431
## 28 4.769678 0.34874244
## 29 5.788688 2.71418112
## 30 4.259518 0.15992700</code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="introduction-and-exploratory-data-analysis.html#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Computation of the mean for each variable of the dataset for group B</span></span>
<span id="cb35-2"><a href="introduction-and-exploratory-data-analysis.html#cb35-2" aria-hidden="true" tabindex="-1"></a>mean.variables.groupB <span class="ot">&lt;-</span> <span class="fu">apply</span>(data.B, <span class="dv">2</span>, mean, <span class="at">na.rm=</span>T)</span>
<span id="cb35-3"><a href="introduction-and-exploratory-data-analysis.html#cb35-3" aria-hidden="true" tabindex="-1"></a>mean.variables.groupB</span></code></pre></div>
<pre><code>##   scoreX   scoreY 
## 5.148834 2.197438</code></pre>
<p>We can see slightly different values for both variables in both groups. However, the mean gives us only information about the central values for both variables. It is important to introduce a measure of variation in order to determine how values are distributed <em>around</em> the mean. To do so, we use the standard deviation.</p>
<p>The standard deviation represents the amount of variation of values around their mean and can be computed as:</p>
<p><span class="math inline">\(\sigma = \sqrt(\frac{\sum_{i}^{N}(x_{i}-\overline{x})^{2}}{N})\)</span></p>
<p>We will now compute the standard deviation for both variables in each group :</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="introduction-and-exploratory-data-analysis.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Computation of the standard deviation for both variables </span></span>
<span id="cb37-2"><a href="introduction-and-exploratory-data-analysis.html#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="co">#of the dataset in group A</span></span>
<span id="cb37-3"><a href="introduction-and-exploratory-data-analysis.html#cb37-3" aria-hidden="true" tabindex="-1"></a>sd.variables.groupA <span class="ot">&lt;-</span> <span class="fu">apply</span>(data.A, <span class="dv">2</span>, sd, <span class="at">na.rm=</span>T)</span>
<span id="cb37-4"><a href="introduction-and-exploratory-data-analysis.html#cb37-4" aria-hidden="true" tabindex="-1"></a>sd.variables.groupA</span></code></pre></div>
<pre><code>##   scoreX   scoreY 
## 1.370947 1.331300</code></pre>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="introduction-and-exploratory-data-analysis.html#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Computation of the standard deviation for both variables</span></span>
<span id="cb39-2"><a href="introduction-and-exploratory-data-analysis.html#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co">#of the dataset in group B</span></span>
<span id="cb39-3"><a href="introduction-and-exploratory-data-analysis.html#cb39-3" aria-hidden="true" tabindex="-1"></a>sd.variables.groupB <span class="ot">&lt;-</span> <span class="fu">apply</span>(data.B, <span class="dv">2</span>, sd, <span class="at">na.rm=</span>T)</span>
<span id="cb39-4"><a href="introduction-and-exploratory-data-analysis.html#cb39-4" aria-hidden="true" tabindex="-1"></a>sd.variables.groupB</span></code></pre></div>
<pre><code>##  scoreX  scoreY 
## 1.14792 1.61810</code></pre>
<p>A large standard deviation indicates that one or several observed values are very different from the mean, while a small standard deviation shows that most values are very close to the mean.</p>
<p>These two measures are very useful to describe a distribution and are very important in statistical testing, as we will see later in the course. However, mean and standard deviation are not perfect to describe all distributions.</p>
<p>Indeed, one weakness of the mean is the lack of robustness to extreme values. The mean can be strongly influenced by the presence of a proportion of extremely large or small values. It is, therefore, not the best summary measure for skewed distributions. In such case, quantiles are preferred.</p>
<p>The median is the quantile of 50%, so it is the value that splits observations into two equal parts. By definition, it is more robust to extreme values: its value is not influenced directly by the extreme values. For example, the median of</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="introduction-and-exploratory-data-analysis.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">:</span><span class="dv">10</span></span></code></pre></div>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10</code></pre>
<p>is 5.5, and is the same as the median of</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="introduction-and-exploratory-data-analysis.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>, <span class="dv">100</span>)</span></code></pre></div>
<pre><code>##  [1]   1   2   3   4   5   6   7   8   9 100</code></pre>
<p>which is 5.5. So, replacing the largest value by an even larger value does not affect the median.</p>
<p>However, the mean is clearly affected: for the first set of values the mean is 5.5, and for the second it is 14.5.</p>
<p>We can compute easily the median in R for multiple columns at once:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="introduction-and-exploratory-data-analysis.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co">#computation of the median for both variables in group A</span></span>
<span id="cb45-2"><a href="introduction-and-exploratory-data-analysis.html#cb45-2" aria-hidden="true" tabindex="-1"></a>median.variables.groupA <span class="ot">&lt;-</span> <span class="fu">apply</span>(data.A, <span class="dv">2</span>, median, <span class="at">na.rm =</span> T)</span>
<span id="cb45-3"><a href="introduction-and-exploratory-data-analysis.html#cb45-3" aria-hidden="true" tabindex="-1"></a>median.variables.groupA</span></code></pre></div>
<pre><code>##   scoreX   scoreY 
## 4.926336 1.596064</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="introduction-and-exploratory-data-analysis.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co">#computation of the median for both variables in group B</span></span>
<span id="cb47-2"><a href="introduction-and-exploratory-data-analysis.html#cb47-2" aria-hidden="true" tabindex="-1"></a>median.variables.groupB <span class="ot">&lt;-</span> <span class="fu">apply</span>(data.B, <span class="dv">2</span>, median, <span class="at">na.rm =</span> T)</span>
<span id="cb47-3"><a href="introduction-and-exploratory-data-analysis.html#cb47-3" aria-hidden="true" tabindex="-1"></a>median.variables.groupB</span></code></pre></div>
<pre><code>##   scoreX   scoreY 
## 5.060254 1.653759</code></pre>
<p>For both variables, the medians per group are close to each other. This is particularly the case for <code>scoreY</code>, which was identified as skewed when plotting the histograms. Due to larger values in group B arising at random, their mean is larger than that for group A. However, the set of values in group A and group B were obtained from the same distribution, so these differences are due to random noise. The median is much less sensitive to such noise.</p>
<p>It can also be of interest to look at the other quantiles of the set of values. Let’s take the variable <code>ScoreY</code> as an example:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="introduction-and-exploratory-data-analysis.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co">#computation of quantile of the variable scoreY for group A</span></span>
<span id="cb49-2"><a href="introduction-and-exploratory-data-analysis.html#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(data.A<span class="sc">$</span>scoreY)</span></code></pre></div>
<pre><code>##         0%        25%        50%        75%       100% 
## 0.06849886 0.48053515 1.59606376 2.63762448 4.49709044</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="introduction-and-exploratory-data-analysis.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co">#computation of quantile of the variable scoreY for group B</span></span>
<span id="cb51-2"><a href="introduction-and-exploratory-data-analysis.html#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(data.B<span class="sc">$</span>scoreY)</span></code></pre></div>
<pre><code>##         0%        25%        50%        75%       100% 
## 0.05282527 0.77458628 1.65375910 3.34040589 5.97353896</code></pre>
<p>By default the function <code>quantile</code> provides the minimum, the maximum and the quartiles of a set of values. In this example we can see that the difference between quantiles in these groups is small until the median. The third quartile and the maximum values explain the difference obtained in the mean for the variable <code>scoreY</code> between group A and group B.</p>
<p>We can also measure the amount of variation using robust meaures. One such measure is the median absolute variation (MAD). It is obtained by calculating the median value of the distance to the median, as described by the formula below:</p>
<p><span class="math inline">\(MAD=\text{median}(|X-\widetilde{X}|)\)</span></p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="introduction-and-exploratory-data-analysis.html#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co">#computation of the median absolute deviation for group A</span></span>
<span id="cb53-2"><a href="introduction-and-exploratory-data-analysis.html#cb53-2" aria-hidden="true" tabindex="-1"></a>mad.variables.groupA <span class="ot">&lt;-</span> <span class="fu">apply</span>(data.A, <span class="dv">2</span>, mad, <span class="at">na.rm =</span>T)</span>
<span id="cb53-3"><a href="introduction-and-exploratory-data-analysis.html#cb53-3" aria-hidden="true" tabindex="-1"></a>mad.variables.groupA</span></code></pre></div>
<pre><code>##   scoreX   scoreY 
## 1.134796 1.626960</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="introduction-and-exploratory-data-analysis.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co">#computation of the median absolute deviation for group A</span></span>
<span id="cb55-2"><a href="introduction-and-exploratory-data-analysis.html#cb55-2" aria-hidden="true" tabindex="-1"></a>mad.variables.groupB <span class="ot">&lt;-</span> <span class="fu">apply</span>(data.B, <span class="dv">2</span>, mad, <span class="at">na.rm =</span>T)</span>
<span id="cb55-3"><a href="introduction-and-exploratory-data-analysis.html#cb55-3" aria-hidden="true" tabindex="-1"></a>mad.variables.groupB</span></code></pre></div>
<pre><code>##   scoreX   scoreY 
## 1.282703 1.723980</code></pre>
<p>To see that this is a more robust measure, let us compute it for:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="introduction-and-exploratory-data-analysis.html#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">:</span><span class="dv">10</span></span></code></pre></div>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10</code></pre>
<p>yielding 3.7065, which is the same as the MAD of</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="introduction-and-exploratory-data-analysis.html#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>, <span class="dv">100</span>)</span></code></pre></div>
<pre><code>##  [1]   1   2   3   4   5   6   7   8   9 100</code></pre>
<p>given by 3.7065.</p>
<hr />
<blockquote>
<p><em>Quick task(s)</em>:</p>
<p>Solve <a href="_book/03-Mean-Variance.tasks.nocode.html">the task(s)</a>, and check your solution(s) <a href="_book/03-Mean-Variance.tasks.code.html">here</a>.</p>
</blockquote>
<hr />
</div>
</div>
<div id="correlation-and-heatmap" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Correlation and heatmap</h2>
<div id="motivation-1" class="section level3" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Motivation</h3>
<p>A next step when analysing data is to ask whether observed variables are related or independent. How can we quantify association? The measure of relatedness between variables is called <strong>correlation</strong>. Several types of correlation exist and they do not measure exactly the same thing. This is what we are going to explore in this section.</p>
</div>
<div id="working-example-2" class="section level3" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Working example</h3>
<p>In the previous section, two unrelated variables were simulated. In this example we will create a dataset by simulating 10 more or less correlated variables.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="introduction-and-exploratory-data-analysis.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mvtnorm)</span>
<span id="cb61-2"><a href="introduction-and-exploratory-data-analysis.html#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">352</span>)</span>
<span id="cb61-3"><a href="introduction-and-exploratory-data-analysis.html#cb61-3" aria-hidden="true" tabindex="-1"></a>sample.size <span class="ot">&lt;-</span> <span class="dv">60</span></span>
<span id="cb61-4"><a href="introduction-and-exploratory-data-analysis.html#cb61-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-5"><a href="introduction-and-exploratory-data-analysis.html#cb61-5" aria-hidden="true" tabindex="-1"></a>corrs <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">45</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb61-6"><a href="introduction-and-exploratory-data-analysis.html#cb61-6" aria-hidden="true" tabindex="-1"></a>corrs.matrix <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb61-7"><a href="introduction-and-exploratory-data-analysis.html#cb61-7" aria-hidden="true" tabindex="-1"></a>corrs.matrix[<span class="fu">upper.tri</span>(corrs.matrix, <span class="at">diag=</span><span class="cn">FALSE</span>)] <span class="ot">&lt;-</span> corrs</span>
<span id="cb61-8"><a href="introduction-and-exploratory-data-analysis.html#cb61-8" aria-hidden="true" tabindex="-1"></a>corrs.matrix[<span class="fu">lower.tri</span>(corrs.matrix, <span class="at">diag=</span><span class="cn">FALSE</span>)]  <span class="ot">&lt;-</span> <span class="fu">t</span>(corrs.matrix)[<span class="fu">lower.tri</span>(corrs.matrix)]</span>
<span id="cb61-9"><a href="introduction-and-exploratory-data-analysis.html#cb61-9" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(corrs.matrix) <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb61-10"><a href="introduction-and-exploratory-data-analysis.html#cb61-10" aria-hidden="true" tabindex="-1"></a>standard.deviations <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>,<span class="dv">10</span>)</span>
<span id="cb61-11"><a href="introduction-and-exploratory-data-analysis.html#cb61-11" aria-hidden="true" tabindex="-1"></a>covs.matrix<span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(Matrix<span class="sc">::</span><span class="fu">nearPD</span>(<span class="fu">diag</span>(standard.deviations) <span class="sc">%*%</span> corrs.matrix <span class="sc">%*%</span> <span class="fu">diag</span>(standard.deviations))<span class="sc">$</span>mat)</span>
<span id="cb61-12"><a href="introduction-and-exploratory-data-analysis.html#cb61-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-13"><a href="introduction-and-exploratory-data-analysis.html#cb61-13" aria-hidden="true" tabindex="-1"></a>dataset<span class="ot">&lt;-</span><span class="fu">as.data.frame</span>(<span class="fu">rmvnorm</span>( sample.size, <span class="at">mean=</span><span class="fu">rep</span>(<span class="dv">0</span>,<span class="dv">10</span>), covs.matrix))</span>
<span id="cb61-14"><a href="introduction-and-exploratory-data-analysis.html#cb61-14" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(dataset) <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&#39;Variable&#39;</span>, <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>), <span class="at">sep=</span><span class="st">&#39;&#39;</span>)</span></code></pre></div>
<p>By definition, the correlation is a measure of association between two variables. It ranges from -1 to 1, is symmetric and scale-invariant. Being symmetric in this case means that the correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is the same as the one between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>. Scale-invariant means that multiplying a set of values of a variable by a positive number (except 0) will not impact the correlation between this variable with any other variable.</p>
<p>Let us look at the following variables:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="introduction-and-exploratory-data-analysis.html#cb62-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">5</span>)</span>
<span id="cb62-2"><a href="introduction-and-exploratory-data-analysis.html#cb62-2" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>## [1]  1.28821371 -1.01602894 -0.27022292  0.02957032 -0.35486645</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="introduction-and-exploratory-data-analysis.html#cb64-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">5</span>)</span>
<span id="cb64-2"><a href="introduction-and-exploratory-data-analysis.html#cb64-2" aria-hidden="true" tabindex="-1"></a>y</span></code></pre></div>
<pre><code>## [1]  0.6278424  0.3978634 -0.8106308 -0.1570483  0.1107076</code></pre>
<p>Their correlation is computed here to illustrate symmetry and scale-invariance:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="introduction-and-exploratory-data-analysis.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(x, y)</span></code></pre></div>
<pre><code>## [1] 0.3129188</code></pre>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="introduction-and-exploratory-data-analysis.html#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(y, x)</span></code></pre></div>
<pre><code>## [1] 0.3129188</code></pre>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="introduction-and-exploratory-data-analysis.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(x, <span class="dv">10</span><span class="sc">*</span>y)</span></code></pre></div>
<pre><code>## [1] 0.3129188</code></pre>
<p>The values -1 and 1 represent perfect (anti) correlation, while 0 represents absence of correlation. Having a negative correlation between two variables means that large values of one variable are associated with small values of the other. These properties are similar for all types of correlation.</p>
<p>Three main correlations are used. The most common one is the <strong>Pearson</strong> correlation, also called linear correlation, which can be computed via the formula:</p>
<p><span class="math inline">\(r = \frac{\sum_{i}(x_i-\overline{x})(y_i-\overline{y})}{\sum_{i}(x_i-\overline{x})^{2}\sum_{i}(y_i-\overline{y})^{2}}\)</span></p>
<p>The Pearson correlation is computed by default by the R function <code>cor</code>:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="introduction-and-exploratory-data-analysis.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co">#computation of the pearson correlation between Variable1 and Variable2</span></span>
<span id="cb72-2"><a href="introduction-and-exploratory-data-analysis.html#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(dataset<span class="sc">$</span>Variable1,dataset<span class="sc">$</span>Variable2, <span class="at">method =</span> <span class="st">&#39;pearson&#39;</span>, <span class="at">use =</span> <span class="st">&#39;complete.obs&#39;</span>)</span></code></pre></div>
<pre><code>## [1] 0.1912684</code></pre>
<p>The absolute value of the correlation 0.1912684 tells us that variation of <code>Variable1</code> does not necessarily mean variation for <code>Variable2</code>. Indeed, a scatterplot of the two variables does not suggest much association:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="introduction-and-exploratory-data-analysis.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dataset<span class="sc">$</span>Variable1, dataset<span class="sc">$</span>Variable2)</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>The function <code>cor</code> can also be used on the entire data matrix, yielding all pairwise correlations between variables:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="introduction-and-exploratory-data-analysis.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co">#computation of the Pearson correlation matrix between all #variables of the dataset</span></span>
<span id="cb75-2"><a href="introduction-and-exploratory-data-analysis.html#cb75-2" aria-hidden="true" tabindex="-1"></a>correlation.pearson <span class="ot">&lt;-</span> <span class="fu">cor</span>(dataset, <span class="at">method =</span> <span class="st">&#39;pearson&#39;</span>, <span class="at">use =</span> <span class="st">&#39;complete.obs&#39;</span>)</span>
<span id="cb75-3"><a href="introduction-and-exploratory-data-analysis.html#cb75-3" aria-hidden="true" tabindex="-1"></a>correlation.pearson</span></code></pre></div>
<pre><code>##              Variable1   Variable2   Variable3   Variable4   Variable5
## Variable1   1.00000000  0.19126844  0.21752224 -0.33142355 -0.03093511
## Variable2   0.19126844  1.00000000 -0.51765078 -0.01337544 -0.49872569
## Variable3   0.21752224 -0.51765078  1.00000000 -0.30235531 -0.07174296
## Variable4  -0.33142355 -0.01337544 -0.30235531  1.00000000 -0.03809821
## Variable5  -0.03093511 -0.49872569 -0.07174296 -0.03809821  1.00000000
## Variable6  -0.53181299 -0.35595914  0.04109194  0.14018466  0.58563977
## Variable7   0.50523610  0.63096198 -0.32476449  0.43999575 -0.33488644
## Variable8  -0.24407265 -0.28430370  0.11700066 -0.14327152 -0.33167843
## Variable9   0.54567571  0.09542881  0.45464382 -0.58902176 -0.17758377
## Variable10 -0.32526502 -0.47960646 -0.13381373  0.25007363  0.45375321
##              Variable6   Variable7  Variable8   Variable9 Variable10
## Variable1  -0.53181299  0.50523610 -0.2440727  0.54567571 -0.3252650
## Variable2  -0.35595914  0.63096198 -0.2843037  0.09542881 -0.4796065
## Variable3   0.04109194 -0.32476449  0.1170007  0.45464382 -0.1338137
## Variable4   0.14018466  0.43999575 -0.1432715 -0.58902176  0.2500736
## Variable5   0.58563977 -0.33488644 -0.3316784 -0.17758377  0.4537532
## Variable6   1.00000000 -0.55376001 -0.5352480 -0.10179077  0.6954481
## Variable7  -0.55376001  1.00000000 -0.2478635  0.02078802 -0.4821684
## Variable8  -0.53524803 -0.24786347  1.0000000 -0.26898602 -0.3316227
## Variable9  -0.10179077  0.02078802 -0.2689860  1.00000000 -0.2663179
## Variable10  0.69544806 -0.48216841 -0.3316227 -0.26631788  1.0000000</code></pre>
<p>A matrix of correlation as we just obtained can provide a lot of information about the variables. However, for illustration in a paper it is better to use a representation of the correlation matrix called <code>heatmap</code>:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="introduction-and-exploratory-data-analysis.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Heatmap plot</span></span>
<span id="cb77-2"><a href="introduction-and-exploratory-data-analysis.html#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gplots)</span></code></pre></div>
<pre><code>## 
## Attachement du package : &#39;gplots&#39;</code></pre>
<pre><code>## L&#39;objet suivant est masqué depuis &#39;package:stats&#39;:
## 
##     lowess</code></pre>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="introduction-and-exploratory-data-analysis.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">heatmap.2</span>(correlation.pearson, <span class="at">trace =</span> <span class="st">&#39;none&#39;</span>, <span class="at">cexRow =</span> <span class="fl">0.8</span>, </span>
<span id="cb80-2"><a href="introduction-and-exploratory-data-analysis.html#cb80-2" aria-hidden="true" tabindex="-1"></a>          <span class="at">cexCol =</span> <span class="fl">0.8</span>, <span class="at">col=</span> <span class="fu">colorRampPalette</span>(<span class="fu">c</span>(<span class="st">&quot;green&quot;</span>,<span class="st">&quot;white&quot;</span>,<span class="st">&quot;red&quot;</span>))(<span class="dv">20</span>))</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<p>Here, the correlation is represented by a ‘heat’, blue or ‘cold heat’ represent negative correlations, red or ‘hot heat’ represent strong correlations.</p>
<p>The trees produced by the function <code>heatmap</code> on each side of the plot represent the similarity between the variables based on their correlation matrix. Each variable has a root, and all roots merge at the base of the tree. The height at which the roots of two variables merge represents the dissimilarity between them. The higher they meet, the more dissimilar they are.</p>
<p>The Pearson correlation is particularly good at quantifying association given a linear relationship between two variables X and Y, i.e., in cases where $ X = aY + b $. However, more complex relationship can exist between variables. Alternative correlation measures can be used to capture other forms of association. However, the interpretation of this correlation can be challenging.</p>
<p>One common alternative is to use <strong>Spearman</strong>’s correlation coefficient. It is non-parametric and often denoted by <span class="math inline">\(\rho\)</span>. The computation is similar to the Pearson correlation, but the values are replaced by their rank. For example, to compute the Spearman correlation coefficient between</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="introduction-and-exploratory-data-analysis.html#cb81-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">7</span>, <span class="dv">2</span>, <span class="dv">5</span>)</span></code></pre></div>
<p>and</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="introduction-and-exploratory-data-analysis.html#cb82-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">4</span>)</span></code></pre></div>
<p>we actually compute the Pearson correlation between the ranks of <span class="math inline">\(x\)</span>:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="introduction-and-exploratory-data-analysis.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rank</span>(x)</span></code></pre></div>
<pre><code>## [1] 3 1 2</code></pre>
<p>and the ranks of <span class="math inline">\(y\)</span>:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="introduction-and-exploratory-data-analysis.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rank</span>(y)</span></code></pre></div>
<pre><code>## [1] 1 3 2</code></pre>
<p>Let us now compute the Spearman’s rank correlation matrix for <code>dataset</code> and plot the <code>heatmap</code>.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="introduction-and-exploratory-data-analysis.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co">#computation of the correlation matrix between all variables of</span></span>
<span id="cb87-2"><a href="introduction-and-exploratory-data-analysis.html#cb87-2" aria-hidden="true" tabindex="-1"></a>correlation.spearman <span class="ot">&lt;-</span> <span class="fu">cor</span>(dataset, <span class="at">method =</span> <span class="st">&#39;spearman&#39;</span>, <span class="at">use =</span> <span class="st">&#39;complete.obs&#39;</span>)</span>
<span id="cb87-3"><a href="introduction-and-exploratory-data-analysis.html#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="fu">heatmap.2</span>(correlation.spearman, <span class="at">trace =</span> <span class="st">&#39;none&#39;</span>, <span class="at">cexRow =</span> <span class="fl">0.8</span>,</span>
<span id="cb87-4"><a href="introduction-and-exploratory-data-analysis.html#cb87-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">cexCol =</span> <span class="fl">0.8</span>, <span class="at">col=</span> <span class="fu">colorRampPalette</span>(<span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>,<span class="st">&quot;white&quot;</span>,<span class="st">&quot;red&quot;</span>))(<span class="dv">20</span>))</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
<p>Here as I have only created linearly correlated variables, not much difference can be seen between both heatmaps. Note that a transformation of the data that does not change the ranks of observations, such as the logarithm or the square root, does not affect the Spearman correlation.</p>
<p>The third correlation coefficient, <strong>Kendall</strong>’s tau represented by <span class="math inline">\(\tau\)</span>, is also nonparametric. Let us consider 2 variables X and Y having 3 observations, (0, 1, 2) and (1, 4, 3) respectively. The 3 subjects have each 2 values, one for each variable, given by (0, 1) for the first, (1, 4) for the second, and (2, 3) for the third. Kendall’s tau will check if each pair of subjects has concordant or discordant observations, and count the number of subjects of each type. In the above example, the second subject (1, 4) involves both entries larger than the first subject (0, 1), so they are called concordant. The third subject (2, 3) involves one entry larger and one smaller than the second subject (1, 4), so they are called discordant. Finally, the third subject (2, 3) is concordant compared with the first (0, 1).</p>
<p>The correlation is then computed as the number of concordant pairs of subjects minus the number of discordant pairs, divided by the total number of pairs. In the above example, there are 2 concordant pairs and one discordant, and the total number of pairs of subjects (combinations of subjects) is equal to 3, leading to a Kendall’s <span class="math inline">\(\tau\)</span> of 1/3=0.333.</p>
<p>This coefficient can be more interpretable than the Spearman’s correlation coefficient.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="introduction-and-exploratory-data-analysis.html#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co">#computation of the correlation matrix between all variables of</span></span>
<span id="cb88-2"><a href="introduction-and-exploratory-data-analysis.html#cb88-2" aria-hidden="true" tabindex="-1"></a>correlation.kendall <span class="ot">&lt;-</span> <span class="fu">cor</span>(dataset, <span class="at">method =</span> <span class="st">&#39;kendall&#39;</span>, <span class="at">use =</span> <span class="st">&#39;complete.obs&#39;</span>)</span>
<span id="cb88-3"><a href="introduction-and-exploratory-data-analysis.html#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="fu">heatmap.2</span>(correlation.kendall, <span class="at">trace =</span> <span class="st">&#39;none&#39;</span>, <span class="at">cexRow =</span> <span class="fl">0.8</span>,</span>
<span id="cb88-4"><a href="introduction-and-exploratory-data-analysis.html#cb88-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">cexCol =</span> <span class="fl">0.8</span>, <span class="at">col=</span> <span class="fu">colorRampPalette</span>(<span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>,<span class="st">&quot;white&quot;</span>,<span class="st">&quot;red&quot;</span>))(<span class="dv">20</span>))</span></code></pre></div>
<p><img src="Medical-Statistics-Course_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<hr />
<blockquote>
<p><em>Quick task(s)</em>:</p>
<p>Solve <a href="_book/04-Correlations.tasks.nocode.html">the task(s)</a>, and check your solution(s) <a href="_book/04-Correlations.tasks.code.html">here</a>.</p>
</blockquote>
<hr />

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="statistical-tests---part-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
